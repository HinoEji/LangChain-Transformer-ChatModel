{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c0a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfea9e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 19:35:08.388026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771097708.410683   35217 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771097708.417470   35217 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771097708.435209   35217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771097708.435232   35217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771097708.435235   35217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771097708.435238   35217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "from transformer_chat_model.chat_models import TransformerChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b2d98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model from hugginface...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd247c1c32245fc80c806d8355c1f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model_name_or_path = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# Create your quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "chat_model = TransformerChatModel(\n",
    "    pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
    "    quantization_config = bnb_config,\n",
    "    max_new_tokens = 1024\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a949499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Donald Trump was the 45th President of the United States, serving from January 20, 2017 to January 20, 2021. He ran for president three times before winning in 2016, and he left office on January 20, 2021.\\n\\nTrump is known for his controversial political views and actions during his presidency. He was a real estate developer and businessman before entering politics. His campaign focused on issues such as immigration, trade, and national security. He was also known for his business acumen and his personal style, which often included dramatic and polarizing statements.\\n\\nDuring his time in office, Trump faced numerous controversies, including allegations of sexual misconduct, executive orders that were met with legal challenges, and conflicts with various world leaders. He also made significant changes to the U.S. government, including the firing of several key cabinet members and the appointment of new ones.\\n\\nAfter leaving office, Trump continued to be involved in various business ventures and has been a frequent target of criticism and scrutiny over his actions and policies.', additional_kwargs={}, response_metadata={}, id='run--f8a078b4-31b8-4782-840e-e658d3568000-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"Tell me about Trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1aaa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa383161",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def factorial(num: int )-> int:\n",
    "    \"\"\"Calculate factorial of a number\"\"\"\n",
    "    res = 1\n",
    "    for i in range(num):\n",
    "        res*=i\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d249185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= chat_model.bind_tools(tools = [factorial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf37526f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={}, id='run--323afb28-ed4a-45b6-858c-643a56a37f31-0', tool_calls=[{'name': 'factorial', 'args': {'num': 5}, 'id': 'lc_7117b2c5-ac08-459c-8b33-36e917fb4ba4', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is 5! ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
